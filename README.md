# Waldo Node Kafka

> Kafka library for Node.

## Install

Install the module using NPM:

```
npm install @waldo/node-kafka --save
```

## Documentation

### The Consumer

The Consumer Constructor is a wrapper around the [kafka-rest package](https://github.com/confluentinc/kafka-rest-node) and its main purpose is to abstract away the kafka-rest interface and cope with connection issues or topic-not-found type of errors behind the scenes. You can now focus on your business.

The constructor requires an object as argument which has the following keys:

* `topic` **String Required** The Kafka topic the consumer will work on.
* `log` **Object Required** A logger to use, must expose the `info` and `error` methods.
* `retryInterval` **Number** How long to wait before retrying a failed connection or topic not found problems, expressed in milliseconds, default: 10 seconds.

```js
const kafkaLib = require('@waldo/node-kafka');
const logger = require('./logger'); // bunyan logger

const consumer = kafkaLib.Consumer({
    topic: 'the-kafka-topic',
    log: logger,
});
```

#### Consumer.connect(opts)

This is the main entry point for consuming kafka messages. The method accepts one argument with options:

* `consumerGroup` **String Required** Define the consumer group.
* `onMessage` **Function Required** Callback to handle single incoming kafka messages.
* `onError` **Function** Callback to handle stream errors.
* `consumerOpts` **Object** Options to pass to kafka-rest consumer instance.

Returns a Promise.

```js
consumer.connect({
    consumerGroup: 'the-consumer-group',
    onMessage: function(data) {},
    onError: function(err) {},
    consumerOpts: {
        // these are the default values used when 'consumerOpts' not set.
        'format': 'avro',
        'auto.commit.enable': true,
        'auto.offset.reset': 'smallest',        
    },
})
    .then(function() {
        console.log('all good');
    })
```

#### Consumer.dispose()

This will destroy the consumer instance safely shutting down the kafka consumer connection.

Returns a Promise which you should wait on to ensure safe shutdown.

### The Producer

A thin wrapper around kafka-rest message producing.

The constructor requires an object as argument which has the following keys:

* `topic` **String** The Kafka topic the producer will emit messages on.
* `schema` **Object** The topic schema as generated by waldo-schema, this needs to be an Object Literal, not an Avro instance.
* `log` **Object** A logger to use, must expose the `info` and `error` methods.

```js
const kafkaLib = require('@waldo/node-kafka');

const logger = require('./logger'); // bunyan logger
const topicSchema = require('./schema');

const producer = kafkaLib.Producer({
    topic: 'the-kafka-topic',
    schema: topicSchema,
    log: logger,
});
```

#### Producer.produce(data)

Produces a log message to kafka using the provided data.

```js
producer.produce({customData: true})
    .then(function() {
        console.log('Produced!');
    })
```

### Helper methods

#### kafkaLib.setKafkaUrl(url)

You can manually define the kafka proxy endpoint using this method. However for this method to take effect you need to invoke it before either any Consumer or Producer ctors have been instantiated.

Node Kafka library will resolve the kafka proxy url using the following rules:

1. Check if any user defined urls have been set using the `setKafkaUrl` method.
2. Check if there is any value set on the env variable `KAFKA_REST_PROXY_URL`.
3. Use the default `http://127.0.0.1:8082` address.

## Release History

- **v0.0.1**, *TBD*
    - Big Bang

## License

Copyright Waldo, Inc. All rights reserved.
